{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1effc72e-2952-4c55-8776-cbacd9f7ff7d",
   "metadata": {},
   "source": [
    "# COMP448 - Medical Image Analysis - Project\n",
    "## Şebnem Demirtaş - 76813\n",
    "## Mete Erdoğan - 69666\n",
    "\n",
    "\n",
    "# - Extreme Learning Machines with PCA\n",
    "#### - Resnet18\n",
    "#### - Resnet50\n",
    "#### - DINO ViT-B/16\n",
    "\n",
    "# - Evaluations of Other Models\n",
    "####      - Resnet18 - Trained From Scratch\n",
    "####      - Resnet18 - Trained after Transfer Learning Initialization\n",
    "####      - Resnet18 - Fine-Tuning the last Linear layer\n",
    "####      - DINO ViT-B/16 - Fine-Tuning with Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5df64aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3432355-4692-4b67-a109-44167410a8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights, resnet18, ResNet18_Weights, resnet101, ResNet101_Weights\n",
    "from torchvision.models import vit_l_16, ViT_L_16_Weights, vit_b_16, ViT_B_16_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b89a9f2-c945-4f0a-9af7-0a7ac7535ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, Counter\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import relu\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split, ConcatDataset\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "104d534d-447e-4b15-85ef-84f29e5b7f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import Pdb\n",
    "import sys\n",
    "import cv2 as cv\n",
    "import pickle\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c61e68d1-3bd1-4693-aab6-14a495e10fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2b5d45c1c2d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "random_seed = 448\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2248d4b-471c-405c-8480-d548e3e0a3eb",
   "metadata": {},
   "source": [
    "### - If the datasets are created and saved, start by loading them from pickle files here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "988e7192-3504-4d47-bee6-32457ed1c809",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_data.pickle\", 'rb') as file:\n",
    "    loaded_data1 = pickle.load(file)\n",
    "    train_dataset = loaded_data1\n",
    "    \n",
    "with open(\"test_data.pickle\", 'rb') as file:\n",
    "    loaded_data2 = pickle.load(file)\n",
    "    test_dataset = loaded_data2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03c82451-3bc4-4327-9008-b52c06ddf7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader2 = DataLoader(train_dataset, batch_size=1, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7656de8f-52be-479a-82e4-6ce9b54b19dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_multiclass(gt_masks, pred_masks, num_classes=3):\n",
    "    gt_masks = gt_masks.float()\n",
    "    pred_masks = pred_masks.float()\n",
    "    metrics = torch.zeros((num_classes, 4))\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        gt_class = (gt_masks == c).float()\n",
    "        pred_class = (pred_masks == c).float()\n",
    "        tp = torch.sum(gt_class * pred_class)\n",
    "        tn = torch.sum((1 - gt_class) * (1 - pred_class))\n",
    "        fp = torch.sum((1 - gt_class) * pred_class)\n",
    "        fn = torch.sum(gt_class * (1 - pred_class))\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else torch.tensor(0.0)\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else torch.tensor(0.0)\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else torch.tensor(0.0)\n",
    "        metrics[c] = torch.tensor([accuracy.item(), precision.item(), recall.item(), f1_score.item()])\n",
    "\n",
    "    acc = torch.sum(gt_masks == pred_masks) / len(pred_masks)\n",
    "    return acc, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adbdb60e-fcd2-473d-8810-f20a7ac94393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_model(model_num = 0):\n",
    "    if(model_num == 4):\n",
    "        model = models.vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1)\n",
    "        print(\"learning rate: \", lr)\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        model.heads.head = nn.Linear(768, 3, bias=True)\n",
    "        return model\n",
    "    \n",
    "    if(model_num == 3):\n",
    "        dino = torch.hub.load('facebookresearch/dino:main', 'dino_vits16')\n",
    "        model = nn.Sequential(collections.OrderedDict([\n",
    "          ('dino', dino),\n",
    "          ('last', nn.Linear(384, 3, bias=True)),\n",
    "        ]))\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        model.last = nn.Linear(384, 3, bias=True)\n",
    "        return model\n",
    "    \n",
    "    if(model_num == 2):\n",
    "        model = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        model.fc = nn.Linear(512, 3, bias=True) \n",
    "        return model\n",
    "        \n",
    "    if(model_num == 1):\n",
    "        return models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "    \n",
    "    else:\n",
    "        return models.resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d7fd0df1-d0e7-4fef-88bc-11db9fd556fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ELM_classifier(train_dataloader2, test_dataloader, X_data, V_best, Wout_best, model):\n",
    "    # Evaluate on Train and Test sets\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    ct = 0\n",
    "    for k, (y, x) in enumerate(train_dataloader2):  \n",
    "        ct+=1\n",
    "        yn = X_data[k,:].to(device)\n",
    "        result = yn @ V_best.to(device) @ Wout_best\n",
    "        pred = torch.argmax(result, dim=0).squeeze()\n",
    "        all_preds.extend([pred.cpu()])\n",
    "        all_labels.extend([x[0].cpu()])\n",
    "    all_preds_tensor = torch.tensor(all_preds)\n",
    "    all_labels_tensor = torch.tensor(all_labels)\n",
    "    acc, metrics = calculate_metrics_multiclass(all_labels_tensor, all_preds_tensor)\n",
    "    print(f'Average Metrics over train dataset:')\n",
    "    print(f'Accuracy: {torch.mean(metrics[:, 0]):.4f}')\n",
    "    print(f'Precision: {torch.mean(metrics[:, 1]):.4f}')\n",
    "    print(f'Recall: {torch.mean(metrics[:, 2]):.4f}')\n",
    "    print(f'F1 Score: {torch.mean(metrics[:, 3]):.4f}')\n",
    "    for c in range(metrics.shape[0]):\n",
    "        print(f'\\nClass {c} Metrics')\n",
    "        print(f'Accuracy: {metrics[c, 0]:.4f}')\n",
    "        print(f'Precision: {metrics[c, 1]:.4f}')\n",
    "        print(f'Recall: {metrics[c, 2]:.4f}')\n",
    "        print(f'F1 Score: {metrics[c, 3]:.4f}')\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    ct = 0\n",
    "    for k, (y, x) in enumerate(test_dataloader):  \n",
    "        ct+=1\n",
    "        yn = model(y.to(device).repeat(1, 3, 1, 1))\n",
    "        result = yn @ V_best.to(device) @ Wout_best\n",
    "        pred = torch.argmax(result, dim=1).squeeze()\n",
    "        all_preds.extend([pred.cpu()])\n",
    "        all_labels.extend([x[0].cpu()])\n",
    "    all_preds_tensor = torch.tensor(all_preds)\n",
    "    all_labels_tensor = torch.tensor(all_labels)\n",
    "    acc, metrics = calculate_metrics_multiclass(all_labels_tensor, all_preds_tensor)\n",
    "    print(f'Average Metrics over test dataset:')\n",
    "    print(f'Accuracy: {torch.mean(metrics[:, 0]):.4f}')\n",
    "    print(f'Precision: {torch.mean(metrics[:, 1]):.4f}')\n",
    "    print(f'Recall: {torch.mean(metrics[:, 2]):.4f}')\n",
    "    print(f'F1 Score: {torch.mean(metrics[:, 3]):.4f}')\n",
    "    for c in range(metrics.shape[0]):\n",
    "        print(f'\\nClass {c} Metrics')\n",
    "        print(f'Accuracy: {metrics[c, 0]:.4f}')\n",
    "        print(f'Precision: {metrics[c, 1]:.4f}')\n",
    "        print(f'Recall: {metrics[c, 2]:.4f}')\n",
    "        print(f'F1 Score: {metrics[c, 3]:.4f}')\n",
    "    \n",
    "    return all_preds_tensor\n",
    "\n",
    "\n",
    "def evaluate_model_x(d1, d2, model):\n",
    "    datatype = torch.float64\n",
    "    model.eval()\n",
    "    print(\"\")\n",
    "    sets = [\"train\", \"test\"]\n",
    "    for idx, dataset in enumerate([d1, d2]):\n",
    "        ct = 0 \n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "        for inputs, labels in dataset:\n",
    "            ct+=1\n",
    "            inputs = inputs.to(device).repeat(1, 3, 1, 1)\n",
    "            labels = labels.to(device)\n",
    "            with torch.set_grad_enabled(False):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, dim=1)\n",
    "                all_preds.extend(preds.cpu())\n",
    "                all_labels.extend(labels.cpu())\n",
    "                #Pdb().set_trace() \n",
    "        all_preds_tensor = torch.tensor(all_preds)\n",
    "        all_labels_tensor = torch.tensor(all_labels)\n",
    "        acc, metrics = calculate_metrics_multiclass(all_labels_tensor, all_preds_tensor)\n",
    "        print(f'Average Metrics over {sets[idx]} dataset:')\n",
    "        print(f'Accuracy: {torch.mean(metrics[:, 0]):.4f}')\n",
    "        print(f'Precision: {torch.mean(metrics[:, 1]):.4f}')\n",
    "        print(f'Recall: {torch.mean(metrics[:, 2]):.4f}')\n",
    "        print(f'F1 Score: {torch.mean(metrics[:, 3]):.4f}')\n",
    "\n",
    "        for c in range(metrics.shape[0]):\n",
    "            print(f'\\nClass {c} Metrics')\n",
    "            print(f'Accuracy: {metrics[c, 0]:.4f}')\n",
    "            print(f'Precision: {metrics[c, 1]:.4f}')\n",
    "            print(f'Recall: {metrics[c, 2]:.4f}')\n",
    "            print(f'F1 Score: {metrics[c, 3]:.4f}')\n",
    "        print()\n",
    "        print()\n",
    "    return all_preds_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69b091b-7843-453d-b567-f588257c8d8a",
   "metadata": {},
   "source": [
    "# DINO - ViT-b16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03815cca-a131-48f1-8f1f-fee1d29c19a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /kuacc/users/merdogan18/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "250\n",
      "500\n",
      "750\n",
      "1000\n",
      "1250\n",
      "1500\n",
      "1750\n",
      "2000\n",
      "2250\n",
      "2500\n",
      "2750\n",
      "3000\n",
      "3250\n",
      "3500\n",
      "3750\n",
      "4000\n",
      "4250\n",
      "4500\n",
      "4750\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torch.hub.load('facebookresearch/dino:main', 'dino_vits16').to(device)\n",
    "torch.set_grad_enabled(False)\n",
    "hidden = 384\n",
    "\n",
    "X_data = torch.zeros((len(train_dataset), hidden), requires_grad=False)\n",
    "b_data = torch.zeros((len(train_dataset), 3), requires_grad=False)\n",
    "\n",
    "for k, (y, x) in enumerate(train_dataloader2):\n",
    "    if(k % 250 == 0):\n",
    "        print(k)\n",
    "    X_data[k, :] = model(y.to(device).repeat(1, 3, 1, 1))\n",
    "    xn = torch.zeros(1, 3).to(device)\n",
    "    xn[:, x] = 1\n",
    "    b_data[k, :] = xn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e7524281-1e1f-4ab7-a103-72570a419d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5216])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_means.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "132f1f9a-3d33-49e4-a00b-84e48a3bea28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- number of pca features: 10\n",
      "Fold 1 with PCA q=10\n",
      "Fold 2 with PCA q=10\n",
      "Fold 3 with PCA q=10\n",
      "Fold 4 with PCA q=10\n",
      "Fold 5 with PCA q=10\n",
      "Average Metrics over 5 folds:\n",
      "Accuracy: 0.8319 ± 0.0112\n",
      "Precision: 0.7294 ± 0.0303\n",
      "Recall: 0.7431 ± 0.0214\n",
      "F1 Score: 0.7311 ± 0.0204\n",
      "\n",
      "Class 0 Metrics over 5 folds:\n",
      "Accuracy: 0.9170 ± 0.0123\n",
      "Precision: 0.7776 ± 0.0269\n",
      "Recall: 0.9487 ± 0.0117\n",
      "F1 Score: 0.8545 ± 0.0195\n",
      "\n",
      "Class 1 Metrics over 5 folds:\n",
      "Accuracy: 0.7966 ± 0.0119\n",
      "Precision: 0.6289 ± 0.0445\n",
      "Recall: 0.5153 ± 0.0392\n",
      "F1 Score: 0.5656 ± 0.0344\n",
      "\n",
      "Class 2 Metrics over 5 folds:\n",
      "Accuracy: 0.7822 ± 0.0094\n",
      "Precision: 0.7816 ± 0.0195\n",
      "Recall: 0.7652 ± 0.0134\n",
      "F1 Score: 0.7731 ± 0.0074\n",
      "----------------------------------------------------\n",
      "\n",
      "- number of pca features: 50\n",
      "Fold 1 with PCA q=50\n",
      "Fold 2 with PCA q=50\n",
      "Fold 3 with PCA q=50\n",
      "Fold 4 with PCA q=50\n",
      "Fold 5 with PCA q=50\n",
      "Average Metrics over 5 folds:\n",
      "Accuracy: 0.8645 ± 0.0077\n",
      "Precision: 0.7889 ± 0.0133\n",
      "Recall: 0.7815 ± 0.0152\n",
      "F1 Score: 0.7793 ± 0.0087\n",
      "\n",
      "Class 0 Metrics over 5 folds:\n",
      "Accuracy: 0.9538 ± 0.0044\n",
      "Precision: 0.8676 ± 0.0105\n",
      "Recall: 0.9681 ± 0.0123\n",
      "F1 Score: 0.9150 ± 0.0041\n",
      "\n",
      "Class 1 Metrics over 5 folds:\n",
      "Accuracy: 0.8221 ± 0.0097\n",
      "Precision: 0.7086 ± 0.0109\n",
      "Recall: 0.5270 ± 0.0191\n",
      "F1 Score: 0.6042 ± 0.0105\n",
      "\n",
      "Class 2 Metrics over 5 folds:\n",
      "Accuracy: 0.8177 ± 0.0090\n",
      "Precision: 0.7903 ± 0.0183\n",
      "Recall: 0.8493 ± 0.0143\n",
      "F1 Score: 0.8186 ± 0.0113\n",
      "----------------------------------------------------\n",
      "\n",
      "- number of pca features: 100\n",
      "Fold 1 with PCA q=100\n",
      "Fold 2 with PCA q=100\n",
      "Fold 3 with PCA q=100\n",
      "Fold 4 with PCA q=100\n",
      "Fold 5 with PCA q=100\n",
      "Average Metrics over 5 folds:\n",
      "Accuracy: 0.8708 ± 0.0080\n",
      "Precision: 0.7984 ± 0.0231\n",
      "Recall: 0.7915 ± 0.0178\n",
      "F1 Score: 0.7905 ± 0.0146\n",
      "\n",
      "Class 0 Metrics over 5 folds:\n",
      "Accuracy: 0.9624 ± 0.0068\n",
      "Precision: 0.8931 ± 0.0191\n",
      "Recall: 0.9706 ± 0.0078\n",
      "F1 Score: 0.9301 ± 0.0103\n",
      "\n",
      "Class 1 Metrics over 5 folds:\n",
      "Accuracy: 0.8234 ± 0.0092\n",
      "Precision: 0.7025 ± 0.0286\n",
      "Recall: 0.5464 ± 0.0328\n",
      "F1 Score: 0.6141 ± 0.0250\n",
      "\n",
      "Class 2 Metrics over 5 folds:\n",
      "Accuracy: 0.8265 ± 0.0080\n",
      "Precision: 0.7996 ± 0.0215\n",
      "Recall: 0.8576 ± 0.0128\n",
      "F1 Score: 0.8273 ± 0.0084\n",
      "----------------------------------------------------\n",
      "\n",
      "- number of pca features: 150\n",
      "Fold 1 with PCA q=150\n",
      "Fold 2 with PCA q=150\n",
      "Fold 3 with PCA q=150\n",
      "Fold 4 with PCA q=150\n",
      "Fold 5 with PCA q=150\n",
      "Average Metrics over 5 folds:\n",
      "Accuracy: 0.8735 ± 0.0103\n",
      "Precision: 0.8032 ± 0.0219\n",
      "Recall: 0.7962 ± 0.0160\n",
      "F1 Score: 0.7955 ± 0.0121\n",
      "\n",
      "Class 0 Metrics over 5 folds:\n",
      "Accuracy: 0.9661 ± 0.0056\n",
      "Precision: 0.9012 ± 0.0129\n",
      "Recall: 0.9757 ± 0.0074\n",
      "F1 Score: 0.9369 ± 0.0066\n",
      "\n",
      "Class 1 Metrics over 5 folds:\n",
      "Accuracy: 0.8250 ± 0.0128\n",
      "Precision: 0.7058 ± 0.0308\n",
      "Recall: 0.5524 ± 0.0285\n",
      "F1 Score: 0.6191 ± 0.0216\n",
      "\n",
      "Class 2 Metrics over 5 folds:\n",
      "Accuracy: 0.8294 ± 0.0125\n",
      "Precision: 0.8028 ± 0.0221\n",
      "Recall: 0.8604 ± 0.0122\n",
      "F1 Score: 0.8303 ± 0.0083\n",
      "----------------------------------------------------\n",
      "\n",
      "- number of pca features: 200\n",
      "Fold 1 with PCA q=200\n",
      "Fold 2 with PCA q=200\n",
      "Fold 3 with PCA q=200\n",
      "Fold 4 with PCA q=200\n",
      "Fold 5 with PCA q=200\n",
      "Average Metrics over 5 folds:\n",
      "Accuracy: 0.8764 ± 0.0119\n",
      "Precision: 0.8088 ± 0.0250\n",
      "Recall: 0.8015 ± 0.0168\n",
      "F1 Score: 0.8014 ± 0.0143\n",
      "\n",
      "Class 0 Metrics over 5 folds:\n",
      "Accuracy: 0.9682 ± 0.0057\n",
      "Precision: 0.9075 ± 0.0130\n",
      "Recall: 0.9766 ± 0.0108\n",
      "F1 Score: 0.9407 ± 0.0063\n",
      "\n",
      "Class 1 Metrics over 5 folds:\n",
      "Accuracy: 0.8290 ± 0.0153\n",
      "Precision: 0.7128 ± 0.0424\n",
      "Recall: 0.5663 ± 0.0240\n",
      "F1 Score: 0.6307 ± 0.0254\n",
      "\n",
      "Class 2 Metrics over 5 folds:\n",
      "Accuracy: 0.8321 ± 0.0147\n",
      "Precision: 0.8060 ± 0.0197\n",
      "Recall: 0.8617 ± 0.0155\n",
      "F1 Score: 0.8328 ± 0.0113\n",
      "----------------------------------------------------\n",
      "\n",
      "- number of pca features: 384\n",
      "Fold 1 with PCA q=384\n",
      "Fold 2 with PCA q=384\n",
      "Fold 3 with PCA q=384\n",
      "Fold 4 with PCA q=384\n",
      "Fold 5 with PCA q=384\n",
      "Average Metrics over 5 folds:\n",
      "Accuracy: 0.8758 ± 0.0078\n",
      "Precision: 0.8080 ± 0.0182\n",
      "Recall: 0.8038 ± 0.0157\n",
      "F1 Score: 0.8033 ± 0.0088\n",
      "\n",
      "Class 0 Metrics over 5 folds:\n",
      "Accuracy: 0.9720 ± 0.0035\n",
      "Precision: 0.9181 ± 0.0063\n",
      "Recall: 0.9787 ± 0.0094\n",
      "F1 Score: 0.9474 ± 0.0030\n",
      "\n",
      "Class 1 Metrics over 5 folds:\n",
      "Accuracy: 0.8278 ± 0.0095\n",
      "Precision: 0.7003 ± 0.0291\n",
      "Recall: 0.5829 ± 0.0255\n",
      "F1 Score: 0.6356 ± 0.0143\n",
      "\n",
      "Class 2 Metrics over 5 folds:\n",
      "Accuracy: 0.8275 ± 0.0106\n",
      "Precision: 0.8055 ± 0.0190\n",
      "Recall: 0.8497 ± 0.0123\n",
      "F1 Score: 0.8269 ± 0.0093\n",
      "----------------------------------------------------\n",
      "\n",
      "Best PCA q: 384 with F1 score: 0.8033\n"
     ]
    }
   ],
   "source": [
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "best_f1 = 0\n",
    "best_model = None\n",
    "best_q = None\n",
    "q_values = [10, 50, 100, 150, 200, 384]  # List of q values to try\n",
    "\n",
    "column_means = torch.mean(X_data, axis=1, keepdim=True)\n",
    "X_zero_mean = X_data - column_means\n",
    "\n",
    "\n",
    "for q in q_values:\n",
    "    print(f\"- number of pca features: {q}\")\n",
    "    fold_metrics = []\n",
    "\n",
    "    for fold, (train_ids, val_ids) in enumerate(kf.split(X_zero_mean)):\n",
    "        print(f'Fold {fold + 1} with PCA q={q}')\n",
    "        \n",
    "        X_train, X_val = X_zero_mean[train_ids], X_zero_mean[val_ids]\n",
    "        b_train, b_val = b_data[train_ids], b_data[val_ids]\n",
    "        U, E, V = torch.pca_lowrank(X_train, q=q, center=True, niter=5)\n",
    "        X_train_pca = X_train @ V\n",
    "        Wout = torch.linalg.pinv(X_train_pca) @ b_train\n",
    "        Wout = Wout.to(device)\n",
    "\n",
    "        all_labels_val = []\n",
    "        all_preds_val = []\n",
    "        V = V.to(device)\n",
    "        for i in range(X_val.shape[0]):\n",
    "            yn = X_val[i, :].to(device)\n",
    "            result = yn @ V @ Wout\n",
    "            pred = torch.argmax(result, dim=0).squeeze()\n",
    "            all_preds_val.extend([pred.cpu()])\n",
    "            all_labels_val.extend([torch.argmax(b_val[i,:]).cpu()])\n",
    "\n",
    "        all_preds_val_tensor = torch.tensor(all_preds_val)\n",
    "        all_labels_val_tensor = torch.tensor(all_labels_val)\n",
    "        acc_val, class_metrics = calculate_metrics_multiclass(all_labels_val_tensor, all_preds_val_tensor)\n",
    "        fold_metrics.append(class_metrics)\n",
    "    \n",
    "    fold_metrics_tensor = torch.stack(fold_metrics)\n",
    "    mean_metrics = torch.mean(fold_metrics_tensor, dim=0)\n",
    "    std_metrics = torch.std(fold_metrics_tensor, dim=0)\n",
    "\n",
    "    print(f'Average Metrics over {num_folds} folds:')\n",
    "    print(f'Accuracy: {torch.mean(mean_metrics[:, 0]):.4f} ± {torch.mean(std_metrics[:, 0]):.4f}')\n",
    "    print(f'Precision: {torch.mean(mean_metrics[:, 1]):.4f} ± {torch.mean(std_metrics[:, 1]):.4f}')\n",
    "    print(f'Recall: {torch.mean(mean_metrics[:, 2]):.4f} ± {torch.mean(std_metrics[:, 2]):.4f}')\n",
    "    print(f'F1 Score: {torch.mean(mean_metrics[:, 3]):.4f} ± {torch.mean(std_metrics[:, 3]):.4f}')\n",
    "\n",
    "    for c in range(mean_metrics.shape[0]):\n",
    "        print(f'\\nClass {c} Metrics over {num_folds} folds:')\n",
    "        print(f'Accuracy: {mean_metrics[c, 0]:.4f} ± {std_metrics[c, 0]:.4f}')\n",
    "        print(f'Precision: {mean_metrics[c, 1]:.4f} ± {std_metrics[c, 1]:.4f}')\n",
    "        print(f'Recall: {mean_metrics[c, 2]:.4f} ± {std_metrics[c, 2]:.4f}')\n",
    "        print(f'F1 Score: {mean_metrics[c, 3]:.4f} ± {std_metrics[c, 3]:.4f}')\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print()\n",
    "    avg_f1 = torch.mean(mean_metrics[:, 3])\n",
    "    if avg_f1 > best_f1:\n",
    "        best_f1 = avg_f1\n",
    "        best_q = q\n",
    "        best_model = (V, Wout)\n",
    "\n",
    "torch.set_grad_enabled(True)\n",
    "print(f\"Best PCA q: {best_q} with F1 score: {best_f1:0.4f}\")\n",
    "\n",
    "# The best model components are in best_model\n",
    "V_best, Wout_best = best_model\n",
    "torch.save((V_best, Wout_best), 'best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1e87139c-8367-4f16-91bf-29be935a637e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metrics over train dataset:\n",
      "Accuracy: 0.8961\n",
      "Precision: 0.8422\n",
      "Recall: 0.8340\n",
      "F1 Score: 0.8359\n",
      "\n",
      "Class 0 Metrics\n",
      "Accuracy: 0.9783\n",
      "Precision: 0.9348\n",
      "Recall: 0.9843\n",
      "F1 Score: 0.9590\n",
      "\n",
      "Class 1 Metrics\n",
      "Accuracy: 0.8549\n",
      "Precision: 0.7602\n",
      "Recall: 0.6387\n",
      "F1 Score: 0.6941\n",
      "\n",
      "Class 2 Metrics\n",
      "Accuracy: 0.8551\n",
      "Precision: 0.8317\n",
      "Recall: 0.8791\n",
      "F1 Score: 0.8547\n",
      "\n",
      "\n",
      "Average Metrics over test dataset:\n",
      "Accuracy: 0.9028\n",
      "Precision: 0.8549\n",
      "Recall: 0.8449\n",
      "F1 Score: 0.8427\n",
      "\n",
      "Class 0 Metrics\n",
      "Accuracy: 0.9054\n",
      "Precision: 0.9834\n",
      "Recall: 0.7607\n",
      "F1 Score: 0.8578\n",
      "\n",
      "Class 1 Metrics\n",
      "Accuracy: 0.8894\n",
      "Precision: 0.7548\n",
      "Recall: 0.7905\n",
      "F1 Score: 0.7723\n",
      "\n",
      "Class 2 Metrics\n",
      "Accuracy: 0.9135\n",
      "Precision: 0.8264\n",
      "Recall: 0.9835\n",
      "F1 Score: 0.8981\n"
     ]
    }
   ],
   "source": [
    "all_preds_tensor1 = evaluate_ELM_classifier(train_dataloader2, test_dataloader, X_zero_mean, V_best, Wout_best, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089791b7-cdd6-40bd-b5e3-ac89856ddae3",
   "metadata": {},
   "source": [
    "# ResNet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a9ffe46f-618d-4126-9a84-2515482c4cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "250\n",
      "500\n",
      "750\n",
      "1000\n",
      "1250\n",
      "1500\n",
      "1750\n",
      "2000\n",
      "2250\n",
      "2500\n",
      "2750\n",
      "3000\n",
      "3250\n",
      "3500\n",
      "3750\n",
      "4000\n",
      "4250\n",
      "4500\n",
      "4750\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "hidden = 512\n",
    "model2 = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "model2.fc = nn.Identity()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model2 = model2.to(device)\n",
    "\n",
    "for param in model2.parameters():\n",
    "    param.requires_grad = False\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "X_data2 = torch.zeros((len(train_dataset), hidden), requires_grad=False)\n",
    "b_data2 = torch.zeros((len(train_dataset), 3), requires_grad=False)\n",
    "\n",
    "for k, (y, x) in enumerate(train_dataloader2):\n",
    "    if k % 250 == 0:\n",
    "        print(k)\n",
    "    y = y.to(device).repeat(1, 3, 1, 1)\n",
    "    X_data2[k, :] = model2(y)\n",
    "    \n",
    "    xn = torch.zeros(1, 3).to(device)\n",
    "    xn[:, x] = 1\n",
    "    b_data2[k, :] = xn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "88ece802-21ca-4ab6-9f9f-d8f2a461caa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- number of pca features: 10\n",
      "Fold 1 with PCA q=10\n",
      "Fold 2 with PCA q=10\n",
      "Fold 3 with PCA q=10\n",
      "Fold 4 with PCA q=10\n",
      "Fold 5 with PCA q=10\n",
      "Average Metrics over 5 folds:\n",
      "Accuracy: 0.7763 ± 0.0190\n",
      "Precision: 0.6652 ± 0.0621\n",
      "Recall: 0.6111 ± 0.0368\n",
      "F1 Score: 0.5716 ± 0.0556\n",
      "\n",
      "Class 0 Metrics over 5 folds:\n",
      "Accuracy: 0.8499 ± 0.0197\n",
      "Precision: 0.6654 ± 0.0518\n",
      "Recall: 0.8382 ± 0.0127\n",
      "F1 Score: 0.7411 ± 0.0356\n",
      "\n",
      "Class 1 Metrics over 5 folds:\n",
      "Accuracy: 0.7559 ± 0.0184\n",
      "Precision: 0.6610 ± 0.1057\n",
      "Recall: 0.1451 ± 0.0772\n",
      "F1 Score: 0.2252 ± 0.1123\n",
      "\n",
      "Class 2 Metrics over 5 folds:\n",
      "Accuracy: 0.7232 ± 0.0190\n",
      "Precision: 0.6692 ± 0.0289\n",
      "Recall: 0.8500 ± 0.0205\n",
      "F1 Score: 0.7484 ± 0.0189\n",
      "----------------------------------------------------\n",
      "\n",
      "- number of pca features: 50\n",
      "Fold 1 with PCA q=50\n",
      "Fold 2 with PCA q=50\n",
      "Fold 3 with PCA q=50\n",
      "Fold 4 with PCA q=50\n",
      "Fold 5 with PCA q=50\n",
      "Average Metrics over 5 folds:\n",
      "Accuracy: 0.7947 ± 0.0107\n",
      "Precision: 0.6844 ± 0.0253\n",
      "Recall: 0.6479 ± 0.0189\n",
      "F1 Score: 0.6361 ± 0.0145\n",
      "\n",
      "Class 0 Metrics over 5 folds:\n",
      "Accuracy: 0.8796 ± 0.0118\n",
      "Precision: 0.7337 ± 0.0173\n",
      "Recall: 0.8361 ± 0.0228\n",
      "F1 Score: 0.7812 ± 0.0084\n",
      "\n",
      "Class 1 Metrics over 5 folds:\n",
      "Accuracy: 0.7717 ± 0.0104\n",
      "Precision: 0.6384 ± 0.0422\n",
      "Recall: 0.2641 ± 0.0156\n",
      "F1 Score: 0.3733 ± 0.0198\n",
      "\n",
      "Class 2 Metrics over 5 folds:\n",
      "Accuracy: 0.7329 ± 0.0099\n",
      "Precision: 0.6811 ± 0.0165\n",
      "Recall: 0.8436 ± 0.0184\n",
      "F1 Score: 0.7536 ± 0.0153\n",
      "----------------------------------------------------\n",
      "\n",
      "- number of pca features: 100\n",
      "Fold 1 with PCA q=100\n",
      "Fold 2 with PCA q=100\n",
      "Fold 3 with PCA q=100\n",
      "Fold 4 with PCA q=100\n",
      "Fold 5 with PCA q=100\n",
      "Average Metrics over 5 folds:\n",
      "Accuracy: 0.7965 ± 0.0101\n",
      "Precision: 0.6816 ± 0.0234\n",
      "Recall: 0.6518 ± 0.0155\n",
      "F1 Score: 0.6398 ± 0.0134\n",
      "\n",
      "Class 0 Metrics over 5 folds:\n",
      "Accuracy: 0.8834 ± 0.0115\n",
      "Precision: 0.7393 ± 0.0197\n",
      "Recall: 0.8446 ± 0.0147\n",
      "F1 Score: 0.7883 ± 0.0128\n",
      "\n",
      "Class 1 Metrics over 5 folds:\n",
      "Accuracy: 0.7688 ± 0.0078\n",
      "Precision: 0.6186 ± 0.0351\n",
      "Recall: 0.2691 ± 0.0108\n",
      "F1 Score: 0.3748 ± 0.0135\n",
      "\n",
      "Class 2 Metrics over 5 folds:\n",
      "Accuracy: 0.7373 ± 0.0111\n",
      "Precision: 0.6869 ± 0.0155\n",
      "Recall: 0.8418 ± 0.0209\n",
      "F1 Score: 0.7564 ± 0.0139\n",
      "----------------------------------------------------\n",
      "\n",
      "- number of pca features: 150\n",
      "Fold 1 with PCA q=150\n",
      "Fold 2 with PCA q=150\n",
      "Fold 3 with PCA q=150\n",
      "Fold 4 with PCA q=150\n",
      "Fold 5 with PCA q=150\n",
      "Average Metrics over 5 folds:\n",
      "Accuracy: 0.8021 ± 0.0085\n",
      "Precision: 0.6927 ± 0.0270\n",
      "Recall: 0.6622 ± 0.0181\n",
      "F1 Score: 0.6529 ± 0.0103\n",
      "\n",
      "Class 0 Metrics over 5 folds:\n",
      "Accuracy: 0.8900 ± 0.0100\n",
      "Precision: 0.7540 ± 0.0243\n",
      "Recall: 0.8494 ± 0.0190\n",
      "F1 Score: 0.7985 ± 0.0130\n",
      "\n",
      "Class 1 Metrics over 5 folds:\n",
      "Accuracy: 0.7732 ± 0.0071\n",
      "Precision: 0.6312 ± 0.0413\n",
      "Recall: 0.2926 ± 0.0104\n",
      "F1 Score: 0.3992 ± 0.0043\n",
      "\n",
      "Class 2 Metrics over 5 folds:\n",
      "Accuracy: 0.7433 ± 0.0084\n",
      "Precision: 0.6930 ± 0.0154\n",
      "Recall: 0.8446 ± 0.0249\n",
      "F1 Score: 0.7611 ± 0.0137\n",
      "----------------------------------------------------\n",
      "\n",
      "- number of pca features: 200\n",
      "Fold 1 with PCA q=200\n",
      "Fold 2 with PCA q=200\n",
      "Fold 3 with PCA q=200\n",
      "Fold 4 with PCA q=200\n",
      "Fold 5 with PCA q=200\n",
      "Average Metrics over 5 folds:\n",
      "Accuracy: 0.8004 ± 0.0095\n",
      "Precision: 0.6834 ± 0.0324\n",
      "Recall: 0.6625 ± 0.0166\n",
      "F1 Score: 0.6529 ± 0.0148\n",
      "\n",
      "Class 0 Metrics over 5 folds:\n",
      "Accuracy: 0.8896 ± 0.0101\n",
      "Precision: 0.7508 ± 0.0230\n",
      "Recall: 0.8546 ± 0.0128\n",
      "F1 Score: 0.7991 ± 0.0097\n",
      "\n",
      "Class 1 Metrics over 5 folds:\n",
      "Accuracy: 0.7682 ± 0.0045\n",
      "Precision: 0.6021 ± 0.0602\n",
      "Recall: 0.3017 ± 0.0091\n",
      "F1 Score: 0.4014 ± 0.0187\n",
      "\n",
      "Class 2 Metrics over 5 folds:\n",
      "Accuracy: 0.7433 ± 0.0139\n",
      "Precision: 0.6973 ± 0.0139\n",
      "Recall: 0.8313 ± 0.0277\n",
      "F1 Score: 0.7582 ± 0.0161\n",
      "----------------------------------------------------\n",
      "\n",
      "- number of pca features: 400\n",
      "Fold 1 with PCA q=400\n",
      "Fold 2 with PCA q=400\n",
      "Fold 3 with PCA q=400\n",
      "Fold 4 with PCA q=400\n",
      "Fold 5 with PCA q=400\n",
      "Average Metrics over 5 folds:\n",
      "Accuracy: 0.7912 ± 0.0084\n",
      "Precision: 0.6607 ± 0.0331\n",
      "Recall: 0.6544 ± 0.0247\n",
      "F1 Score: 0.6470 ± 0.0182\n",
      "\n",
      "Class 0 Metrics over 5 folds:\n",
      "Accuracy: 0.8865 ± 0.0105\n",
      "Precision: 0.7509 ± 0.0219\n",
      "Recall: 0.8362 ± 0.0174\n",
      "F1 Score: 0.7910 ± 0.0123\n",
      "\n",
      "Class 1 Metrics over 5 folds:\n",
      "Accuracy: 0.7515 ± 0.0057\n",
      "Precision: 0.5325 ± 0.0639\n",
      "Recall: 0.3292 ± 0.0238\n",
      "F1 Score: 0.4054 ± 0.0249\n",
      "\n",
      "Class 2 Metrics over 5 folds:\n",
      "Accuracy: 0.7354 ± 0.0090\n",
      "Precision: 0.6988 ± 0.0136\n",
      "Recall: 0.7977 ± 0.0329\n",
      "F1 Score: 0.7447 ± 0.0175\n",
      "----------------------------------------------------\n",
      "\n",
      "- number of pca features: 512\n",
      "Fold 1 with PCA q=512\n",
      "Fold 2 with PCA q=512\n",
      "Fold 3 with PCA q=512\n",
      "Fold 4 with PCA q=512\n",
      "Fold 5 with PCA q=512\n",
      "Average Metrics over 5 folds:\n",
      "Accuracy: 0.7845 ± 0.0066\n",
      "Precision: 0.6517 ± 0.0344\n",
      "Recall: 0.6490 ± 0.0244\n",
      "F1 Score: 0.6433 ± 0.0179\n",
      "\n",
      "Class 0 Metrics over 5 folds:\n",
      "Accuracy: 0.8827 ± 0.0089\n",
      "Precision: 0.7474 ± 0.0347\n",
      "Recall: 0.8222 ± 0.0187\n",
      "F1 Score: 0.7824 ± 0.0138\n",
      "\n",
      "Class 1 Metrics over 5 folds:\n",
      "Accuracy: 0.7465 ± 0.0039\n",
      "Precision: 0.5141 ± 0.0530\n",
      "Recall: 0.3522 ± 0.0258\n",
      "F1 Score: 0.4169 ± 0.0256\n",
      "\n",
      "Class 2 Metrics over 5 folds:\n",
      "Accuracy: 0.7243 ± 0.0071\n",
      "Precision: 0.6937 ± 0.0155\n",
      "Recall: 0.7726 ± 0.0286\n",
      "F1 Score: 0.7307 ± 0.0143\n",
      "----------------------------------------------------\n",
      "\n",
      "Best PCA q: 150 with F1 score: 0.6529\n"
     ]
    }
   ],
   "source": [
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "best_f1 = 0\n",
    "best_model = None\n",
    "best_q = None\n",
    "q_values = [10, 50, 100, 150, 200, 400, 512]  # List of q values to try\n",
    "column_means2 = torch.mean(X_data2, axis=1, keepdim=True)\n",
    "X2_zero_mean = X_data2 - column_means2\n",
    "\n",
    "for q in q_values:\n",
    "    print(f\"- number of pca features: {q}\")\n",
    "    fold_metrics = []\n",
    "\n",
    "    for fold, (train_ids, val_ids) in enumerate(kf.split(X2_zero_mean)):\n",
    "        print(f'Fold {fold + 1} with PCA q={q}')\n",
    "        \n",
    "        X_train, X_val = X2_zero_mean[train_ids], X2_zero_mean[val_ids]\n",
    "        b_train, b_val = b_data2[train_ids], b_data2[val_ids]\n",
    "        U, E, V = torch.pca_lowrank(X_train, q=q, center=True, niter=5)\n",
    "        X_train_pca = X_train @ V\n",
    "        Wout = torch.linalg.pinv(X_train_pca) @ b_train\n",
    "        Wout = Wout.to(device)\n",
    "\n",
    "        all_labels_val = []\n",
    "        all_preds_val = []\n",
    "        V = V.to(device)\n",
    "        for i in range(X_val.shape[0]):\n",
    "            yn = X_val[i, :].to(device)\n",
    "            result = yn @ V @ Wout\n",
    "            pred = torch.argmax(result, dim=0).squeeze()\n",
    "            all_preds_val.extend([pred.cpu()])\n",
    "            all_labels_val.extend([torch.argmax(b_val[i,:]).cpu()])\n",
    "\n",
    "        all_preds_val_tensor = torch.tensor(all_preds_val)\n",
    "        all_labels_val_tensor = torch.tensor(all_labels_val)\n",
    "        acc_val, class_metrics = calculate_metrics_multiclass(all_labels_val_tensor, all_preds_val_tensor)\n",
    "        fold_metrics.append(class_metrics)\n",
    "    \n",
    "    fold_metrics_tensor = torch.stack(fold_metrics)\n",
    "    mean_metrics = torch.mean(fold_metrics_tensor, dim=0)\n",
    "    std_metrics = torch.std(fold_metrics_tensor, dim=0)\n",
    "\n",
    "    print(f'Average Metrics over {num_folds} folds:')\n",
    "    print(f'Accuracy: {torch.mean(mean_metrics[:, 0]):.4f} ± {torch.mean(std_metrics[:, 0]):.4f}')\n",
    "    print(f'Precision: {torch.mean(mean_metrics[:, 1]):.4f} ± {torch.mean(std_metrics[:, 1]):.4f}')\n",
    "    print(f'Recall: {torch.mean(mean_metrics[:, 2]):.4f} ± {torch.mean(std_metrics[:, 2]):.4f}')\n",
    "    print(f'F1 Score: {torch.mean(mean_metrics[:, 3]):.4f} ± {torch.mean(std_metrics[:, 3]):.4f}')\n",
    "\n",
    "    for c in range(mean_metrics.shape[0]):\n",
    "        print(f'\\nClass {c} Metrics over {num_folds} folds:')\n",
    "        print(f'Accuracy: {mean_metrics[c, 0]:.4f} ± {std_metrics[c, 0]:.4f}')\n",
    "        print(f'Precision: {mean_metrics[c, 1]:.4f} ± {std_metrics[c, 1]:.4f}')\n",
    "        print(f'Recall: {mean_metrics[c, 2]:.4f} ± {std_metrics[c, 2]:.4f}')\n",
    "        print(f'F1 Score: {mean_metrics[c, 3]:.4f} ± {std_metrics[c, 3]:.4f}')\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print()\n",
    "    avg_f1 = torch.mean(mean_metrics[:, 3])\n",
    "    if avg_f1 > best_f1:\n",
    "        best_f1 = avg_f1\n",
    "        best_q = q\n",
    "        best_model = (V, Wout)\n",
    "\n",
    "torch.set_grad_enabled(True)\n",
    "print(f\"Best PCA q: {best_q} with F1 score: {best_f1:0.4f}\")\n",
    "\n",
    "# The best model components are in best_model\n",
    "V_best, Wout_best = best_model\n",
    "torch.save((V_best, Wout_best), 'best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "53879139-85ed-4d44-aeca-be2f03182929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metrics over train dataset:\n",
      "Accuracy: 0.8099\n",
      "Precision: 0.7068\n",
      "Recall: 0.6756\n",
      "F1 Score: 0.6685\n",
      "\n",
      "Class 0 Metrics\n",
      "Accuracy: 0.8934\n",
      "Precision: 0.7587\n",
      "Recall: 0.8583\n",
      "F1 Score: 0.8055\n",
      "\n",
      "Class 1 Metrics\n",
      "Accuracy: 0.7812\n",
      "Precision: 0.6560\n",
      "Recall: 0.3190\n",
      "F1 Score: 0.4292\n",
      "\n",
      "Class 2 Metrics\n",
      "Accuracy: 0.7552\n",
      "Precision: 0.7057\n",
      "Recall: 0.8494\n",
      "F1 Score: 0.7709\n",
      "\n",
      "\n",
      "Average Metrics over test dataset:\n",
      "Accuracy: 0.7906\n",
      "Precision: 0.7070\n",
      "Recall: 0.6523\n",
      "F1 Score: 0.6569\n",
      "\n",
      "Class 0 Metrics\n",
      "Accuracy: 0.8093\n",
      "Precision: 0.8286\n",
      "Recall: 0.6197\n",
      "F1 Score: 0.7090\n",
      "\n",
      "Class 1 Metrics\n",
      "Accuracy: 0.8157\n",
      "Precision: 0.6737\n",
      "Recall: 0.4324\n",
      "F1 Score: 0.5267\n",
      "\n",
      "Class 2 Metrics\n",
      "Accuracy: 0.7468\n",
      "Precision: 0.6186\n",
      "Recall: 0.9050\n",
      "F1 Score: 0.7349\n"
     ]
    }
   ],
   "source": [
    "all_preds_tensor2 = evaluate_ELM_classifier(train_dataloader2, test_dataloader, X2_zero_mean, V_best, Wout_best, model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb94580-b7fe-4217-8f2b-16f8d8e429b2",
   "metadata": {},
   "source": [
    "# ResNet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1fcb8d1a-7db2-43e0-93f4-fbbbef864409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "250\n",
      "500\n",
      "750\n",
      "1000\n",
      "1250\n",
      "1500\n",
      "1750\n",
      "2000\n",
      "2250\n",
      "2500\n",
      "2750\n",
      "3000\n",
      "3250\n",
      "3500\n",
      "3750\n",
      "4000\n",
      "4250\n",
      "4500\n",
      "4750\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "hidden = 2048\n",
    "model3 = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "model3.fc = nn.Identity()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model3 = model3.to(device)\n",
    "\n",
    "for param in model3.parameters():\n",
    "    param.requires_grad = False\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "X_data3 = torch.zeros((len(train_dataset), hidden), requires_grad=False)\n",
    "b_data3 = torch.zeros((len(train_dataset), 3), requires_grad=False)\n",
    "\n",
    "for k, (y, x) in enumerate(train_dataloader2):\n",
    "    if k % 250 == 0:\n",
    "        print(k)\n",
    "    y = y.to(device).repeat(1, 3, 1, 1)\n",
    "    X_data3[k, :] = model3(y)\n",
    "    \n",
    "    xn = torch.zeros(1, 3).to(device)\n",
    "    xn[:, x] = 1\n",
    "    b_data3[k, :] = xn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "2d22f648-fa9e-47f8-9efc-7e69e14fd4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- number of pca features: 10\n",
      "Fold 1 with PCA q=10\n",
      "Fold 2 with PCA q=10\n",
      "Fold 3 with PCA q=10\n",
      "Fold 4 with PCA q=10\n",
      "Fold 5 with PCA q=10\n",
      "Average Metrics over 5 folds:\n",
      "Accuracy: 0.7887 ± 0.0190\n",
      "Precision: 0.6765 ± 0.0432\n",
      "Recall: 0.6391 ± 0.0310\n",
      "F1 Score: 0.6173 ± 0.0336\n",
      "\n",
      "Class 0 Metrics over 5 folds:\n",
      "Accuracy: 0.8595 ± 0.0178\n",
      "Precision: 0.6828 ± 0.0393\n",
      "Recall: 0.8485 ± 0.0235\n",
      "F1 Score: 0.7564 ± 0.0311\n",
      "\n",
      "Class 1 Metrics over 5 folds:\n",
      "Accuracy: 0.7697 ± 0.0199\n",
      "Precision: 0.6577 ± 0.0570\n",
      "Recall: 0.2330 ± 0.0466\n",
      "F1 Score: 0.3409 ± 0.0484\n",
      "\n",
      "Class 2 Metrics over 5 folds:\n",
      "Accuracy: 0.7370 ± 0.0192\n",
      "Precision: 0.6890 ± 0.0334\n",
      "Recall: 0.8357 ± 0.0229\n",
      "F1 Score: 0.7547 ± 0.0214\n",
      "----------------------------------------------------\n",
      "\n",
      "- number of pca features: 50\n",
      "Fold 1 with PCA q=50\n",
      "Fold 2 with PCA q=50\n",
      "Fold 3 with PCA q=50\n",
      "Fold 4 with PCA q=50\n",
      "Fold 5 with PCA q=50\n",
      "Average Metrics over 5 folds:\n",
      "Accuracy: 0.8239 ± 0.0130\n",
      "Precision: 0.7308 ± 0.0336\n",
      "Recall: 0.7057 ± 0.0172\n",
      "F1 Score: 0.7007 ± 0.0191\n",
      "\n",
      "Class 0 Metrics over 5 folds:\n",
      "Accuracy: 0.9015 ± 0.0088\n",
      "Precision: 0.7663 ± 0.0273\n",
      "Recall: 0.8873 ± 0.0054\n",
      "F1 Score: 0.8222 ± 0.0176\n",
      "\n",
      "Class 1 Metrics over 5 folds:\n",
      "Accuracy: 0.7981 ± 0.0142\n",
      "Precision: 0.6949 ± 0.0422\n",
      "Recall: 0.3907 ± 0.0276\n",
      "F1 Score: 0.4990 ± 0.0208\n",
      "\n",
      "Class 2 Metrics over 5 folds:\n",
      "Accuracy: 0.7721 ± 0.0161\n",
      "Precision: 0.7310 ± 0.0312\n",
      "Recall: 0.8391 ± 0.0186\n",
      "F1 Score: 0.7809 ± 0.0190\n",
      "----------------------------------------------------\n",
      "\n",
      "- number of pca features: 100\n",
      "Fold 1 with PCA q=100\n",
      "Fold 2 with PCA q=100\n",
      "Fold 3 with PCA q=100\n",
      "Fold 4 with PCA q=100\n",
      "Fold 5 with PCA q=100\n",
      "Average Metrics over 5 folds:\n",
      "Accuracy: 0.8307 ± 0.0132\n",
      "Precision: 0.7392 ± 0.0316\n",
      "Recall: 0.7161 ± 0.0155\n",
      "F1 Score: 0.7121 ± 0.0171\n",
      "\n",
      "Class 0 Metrics over 5 folds:\n",
      "Accuracy: 0.9149 ± 0.0081\n",
      "Precision: 0.7945 ± 0.0246\n",
      "Recall: 0.9022 ± 0.0094\n",
      "F1 Score: 0.8448 ± 0.0163\n",
      "\n",
      "Class 1 Metrics over 5 folds:\n",
      "Accuracy: 0.7972 ± 0.0149\n",
      "Precision: 0.6857 ± 0.0402\n",
      "Recall: 0.3981 ± 0.0223\n",
      "F1 Score: 0.5028 ± 0.0150\n",
      "\n",
      "Class 2 Metrics over 5 folds:\n",
      "Accuracy: 0.7799 ± 0.0167\n",
      "Precision: 0.7374 ± 0.0300\n",
      "Recall: 0.8481 ± 0.0148\n",
      "F1 Score: 0.7886 ± 0.0201\n",
      "----------------------------------------------------\n",
      "\n",
      "- number of pca features: 500\n",
      "Fold 1 with PCA q=500\n",
      "Fold 2 with PCA q=500\n",
      "Fold 3 with PCA q=500\n",
      "Fold 4 with PCA q=500\n",
      "Fold 5 with PCA q=500\n",
      "Average Metrics over 5 folds:\n",
      "Accuracy: 0.8323 ± 0.0112\n",
      "Precision: 0.7358 ± 0.0290\n",
      "Recall: 0.7235 ± 0.0199\n",
      "F1 Score: 0.7205 ± 0.0183\n",
      "\n",
      "Class 0 Metrics over 5 folds:\n",
      "Accuracy: 0.9195 ± 0.0080\n",
      "Precision: 0.8088 ± 0.0222\n",
      "Recall: 0.8991 ± 0.0112\n",
      "F1 Score: 0.8515 ± 0.0163\n",
      "\n",
      "Class 1 Metrics over 5 folds:\n",
      "Accuracy: 0.7937 ± 0.0128\n",
      "Precision: 0.6501 ± 0.0360\n",
      "Recall: 0.4360 ± 0.0351\n",
      "F1 Score: 0.5208 ± 0.0240\n",
      "\n",
      "Class 2 Metrics over 5 folds:\n",
      "Accuracy: 0.7837 ± 0.0128\n",
      "Precision: 0.7484 ± 0.0288\n",
      "Recall: 0.8355 ± 0.0134\n",
      "F1 Score: 0.7892 ± 0.0146\n",
      "----------------------------------------------------\n",
      "\n",
      "- number of pca features: 750\n",
      "Fold 1 with PCA q=750\n",
      "Fold 2 with PCA q=750\n",
      "Fold 3 with PCA q=750\n",
      "Fold 4 with PCA q=750\n",
      "Fold 5 with PCA q=750\n",
      "Average Metrics over 5 folds:\n",
      "Accuracy: 0.8273 ± 0.0076\n",
      "Precision: 0.7254 ± 0.0279\n",
      "Recall: 0.7203 ± 0.0188\n",
      "F1 Score: 0.7172 ± 0.0164\n",
      "\n",
      "Class 0 Metrics over 5 folds:\n",
      "Accuracy: 0.9214 ± 0.0090\n",
      "Precision: 0.8158 ± 0.0270\n",
      "Recall: 0.8969 ± 0.0106\n",
      "F1 Score: 0.8543 ± 0.0176\n",
      "\n",
      "Class 1 Metrics over 5 folds:\n",
      "Accuracy: 0.7851 ± 0.0072\n",
      "Precision: 0.6135 ± 0.0332\n",
      "Recall: 0.4515 ± 0.0321\n",
      "F1 Score: 0.5191 ± 0.0213\n",
      "\n",
      "Class 2 Metrics over 5 folds:\n",
      "Accuracy: 0.7755 ± 0.0066\n",
      "Precision: 0.7471 ± 0.0237\n",
      "Recall: 0.8125 ± 0.0138\n",
      "F1 Score: 0.7781 ± 0.0104\n",
      "----------------------------------------------------\n",
      "\n",
      "- number of pca features: 1000\n",
      "Fold 1 with PCA q=1000\n",
      "Fold 2 with PCA q=1000\n",
      "Fold 3 with PCA q=1000\n",
      "Fold 4 with PCA q=1000\n",
      "Fold 5 with PCA q=1000\n",
      "Average Metrics over 5 folds:\n",
      "Accuracy: 0.8179 ± 0.0103\n",
      "Precision: 0.7099 ± 0.0258\n",
      "Recall: 0.7095 ± 0.0166\n",
      "F1 Score: 0.7060 ± 0.0132\n",
      "\n",
      "Class 0 Metrics over 5 folds:\n",
      "Accuracy: 0.9189 ± 0.0080\n",
      "Precision: 0.8136 ± 0.0205\n",
      "Recall: 0.8881 ± 0.0196\n",
      "F1 Score: 0.8491 ± 0.0159\n",
      "\n",
      "Class 1 Metrics over 5 folds:\n",
      "Accuracy: 0.7734 ± 0.0114\n",
      "Precision: 0.5779 ± 0.0301\n",
      "Recall: 0.4532 ± 0.0139\n",
      "F1 Score: 0.5074 ± 0.0086\n",
      "\n",
      "Class 2 Metrics over 5 folds:\n",
      "Accuracy: 0.7613 ± 0.0114\n",
      "Precision: 0.7382 ± 0.0269\n",
      "Recall: 0.7872 ± 0.0163\n",
      "F1 Score: 0.7616 ± 0.0152\n",
      "----------------------------------------------------\n",
      "\n",
      "- number of pca features: 1500\n",
      "Fold 1 with PCA q=1500\n",
      "Fold 2 with PCA q=1500\n",
      "Fold 3 with PCA q=1500\n",
      "Fold 4 with PCA q=1500\n",
      "Fold 5 with PCA q=1500\n",
      "Average Metrics over 5 folds:\n",
      "Accuracy: 0.7933 ± 0.0093\n",
      "Precision: 0.6726 ± 0.0231\n",
      "Recall: 0.6744 ± 0.0164\n",
      "F1 Score: 0.6721 ± 0.0119\n",
      "\n",
      "Class 0 Metrics over 5 folds:\n",
      "Accuracy: 0.9007 ± 0.0050\n",
      "Precision: 0.7908 ± 0.0160\n",
      "Recall: 0.8344 ± 0.0154\n",
      "F1 Score: 0.8119 ± 0.0112\n",
      "\n",
      "Class 1 Metrics over 5 folds:\n",
      "Accuracy: 0.7469 ± 0.0136\n",
      "Precision: 0.5114 ± 0.0305\n",
      "Recall: 0.4441 ± 0.0120\n",
      "F1 Score: 0.4748 ± 0.0119\n",
      "\n",
      "Class 2 Metrics over 5 folds:\n",
      "Accuracy: 0.7324 ± 0.0093\n",
      "Precision: 0.7155 ± 0.0229\n",
      "Recall: 0.7447 ± 0.0219\n",
      "F1 Score: 0.7294 ± 0.0126\n",
      "----------------------------------------------------\n",
      "\n",
      "- number of pca features: 2048\n",
      "Fold 1 with PCA q=2048\n",
      "Fold 2 with PCA q=2048\n",
      "Fold 3 with PCA q=2048\n",
      "Fold 4 with PCA q=2048\n",
      "Fold 5 with PCA q=2048\n",
      "Average Metrics over 5 folds:\n",
      "Accuracy: 0.7593 ± 0.0104\n",
      "Precision: 0.6266 ± 0.0310\n",
      "Recall: 0.6302 ± 0.0232\n",
      "F1 Score: 0.6276 ± 0.0182\n",
      "\n",
      "Class 0 Metrics over 5 folds:\n",
      "Accuracy: 0.8694 ± 0.0084\n",
      "Precision: 0.7393 ± 0.0231\n",
      "Recall: 0.7606 ± 0.0171\n",
      "F1 Score: 0.7496 ± 0.0165\n",
      "\n",
      "Class 1 Metrics over 5 folds:\n",
      "Accuracy: 0.7170 ± 0.0090\n",
      "Precision: 0.4537 ± 0.0493\n",
      "Recall: 0.4588 ± 0.0246\n",
      "F1 Score: 0.4548 ± 0.0254\n",
      "\n",
      "Class 2 Metrics over 5 folds:\n",
      "Accuracy: 0.6915 ± 0.0140\n",
      "Precision: 0.6867 ± 0.0206\n",
      "Recall: 0.6711 ± 0.0277\n",
      "F1 Score: 0.6783 ± 0.0127\n",
      "----------------------------------------------------\n",
      "\n",
      "Best PCA q: 500 with F1 score: 0.7205\n"
     ]
    }
   ],
   "source": [
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=448)\n",
    "best_f1 = 0\n",
    "best_model = None\n",
    "best_q = None\n",
    "q_values = [10, 50, 100, 500, 750, 1000, 1500, 2048]  # List of q values to try\n",
    "column_means3 = torch.mean(X_data3, axis=1, keepdim=True)\n",
    "X3_zero_mean = X_data3 - column_means3\n",
    "\n",
    "for q in q_values:\n",
    "    print(f\"- number of pca features: {q}\")\n",
    "    fold_metrics = []\n",
    "\n",
    "    for fold, (train_ids, val_ids) in enumerate(kf.split(X3_zero_mean)):\n",
    "        print(f'Fold {fold + 1} with PCA q={q}')\n",
    "        \n",
    "        X_train, X_val = X3_zero_mean[train_ids], X3_zero_mean[val_ids]\n",
    "        b_train, b_val = b_data3[train_ids], b_data3[val_ids]\n",
    "        U, E, V = torch.pca_lowrank(X_train, q=q, center=True, niter=5)\n",
    "        X_train_pca = X_train @ V\n",
    "        Wout = torch.linalg.pinv(X_train_pca) @ b_train\n",
    "        Wout = Wout.to(device)\n",
    "\n",
    "        all_labels_val = []\n",
    "        all_preds_val = []\n",
    "        V = V.to(device)\n",
    "        for i in range(X_val.shape[0]):\n",
    "            yn = X_val[i, :].to(device)\n",
    "            result = yn @ V @ Wout\n",
    "            pred = torch.argmax(result, dim=0).squeeze()\n",
    "            all_preds_val.extend([pred.cpu()])\n",
    "            all_labels_val.extend([torch.argmax(b_val[i,:]).cpu()])\n",
    "\n",
    "        all_preds_val_tensor = torch.tensor(all_preds_val)\n",
    "        all_labels_val_tensor = torch.tensor(all_labels_val)\n",
    "        acc_val, class_metrics = calculate_metrics_multiclass(all_labels_val_tensor, all_preds_val_tensor)\n",
    "        fold_metrics.append(class_metrics)\n",
    "    \n",
    "    fold_metrics_tensor = torch.stack(fold_metrics)\n",
    "    mean_metrics = torch.mean(fold_metrics_tensor, dim=0)\n",
    "    std_metrics = torch.std(fold_metrics_tensor, dim=0)\n",
    "\n",
    "    print(f'Average Metrics over {num_folds} folds:')\n",
    "    print(f'Accuracy: {torch.mean(mean_metrics[:, 0]):.4f} ± {torch.mean(std_metrics[:, 0]):.4f}')\n",
    "    print(f'Precision: {torch.mean(mean_metrics[:, 1]):.4f} ± {torch.mean(std_metrics[:, 1]):.4f}')\n",
    "    print(f'Recall: {torch.mean(mean_metrics[:, 2]):.4f} ± {torch.mean(std_metrics[:, 2]):.4f}')\n",
    "    print(f'F1 Score: {torch.mean(mean_metrics[:, 3]):.4f} ± {torch.mean(std_metrics[:, 3]):.4f}')\n",
    "\n",
    "    for c in range(mean_metrics.shape[0]):\n",
    "        print(f'\\nClass {c} Metrics over {num_folds} folds:')\n",
    "        print(f'Accuracy: {mean_metrics[c, 0]:.4f} ± {std_metrics[c, 0]:.4f}')\n",
    "        print(f'Precision: {mean_metrics[c, 1]:.4f} ± {std_metrics[c, 1]:.4f}')\n",
    "        print(f'Recall: {mean_metrics[c, 2]:.4f} ± {std_metrics[c, 2]:.4f}')\n",
    "        print(f'F1 Score: {mean_metrics[c, 3]:.4f} ± {std_metrics[c, 3]:.4f}')\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print()\n",
    "    avg_f1 = torch.mean(mean_metrics[:, 3])\n",
    "    if avg_f1 > best_f1:\n",
    "        best_f1 = avg_f1\n",
    "        best_q = q\n",
    "        best_model = (V, Wout)\n",
    "\n",
    "torch.set_grad_enabled(True)\n",
    "print(f\"Best PCA q: {best_q} with F1 score: {best_f1:0.4f}\")\n",
    "\n",
    "# The best model components are in best_model\n",
    "V_best, Wout_best = best_model\n",
    "torch.save((V_best, Wout_best), 'best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "22bce8df-9bc6-4b3c-8da5-3136afc715b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metrics over train dataset:\n",
      "Accuracy: 0.8645\n",
      "Precision: 0.7910\n",
      "Recall: 0.7787\n",
      "F1 Score: 0.7799\n",
      "\n",
      "Class 0 Metrics\n",
      "Accuracy: 0.9434\n",
      "Precision: 0.8607\n",
      "Recall: 0.9306\n",
      "F1 Score: 0.8943\n",
      "\n",
      "Class 1 Metrics\n",
      "Accuracy: 0.8286\n",
      "Precision: 0.7213\n",
      "Recall: 0.5465\n",
      "F1 Score: 0.6218\n",
      "\n",
      "Class 2 Metrics\n",
      "Accuracy: 0.8215\n",
      "Precision: 0.7910\n",
      "Recall: 0.8589\n",
      "F1 Score: 0.8236\n",
      "\n",
      "\n",
      "Average Metrics over test dataset:\n",
      "Accuracy: 0.8184\n",
      "Precision: 0.7409\n",
      "Recall: 0.7159\n",
      "F1 Score: 0.7137\n",
      "\n",
      "Class 0 Metrics\n",
      "Accuracy: 0.8189\n",
      "Precision: 0.8854\n",
      "Recall: 0.5940\n",
      "F1 Score: 0.7110\n",
      "\n",
      "Class 1 Metrics\n",
      "Accuracy: 0.8349\n",
      "Precision: 0.6531\n",
      "Recall: 0.6486\n",
      "F1 Score: 0.6508\n",
      "\n",
      "Class 2 Metrics\n",
      "Accuracy: 0.8013\n",
      "Precision: 0.6844\n",
      "Recall: 0.9050\n",
      "F1 Score: 0.7794\n"
     ]
    }
   ],
   "source": [
    "all_preds_tensor3 = evaluate_ELM_classifier(train_dataloader2, test_dataloader, X3_zero_mean, V_best, Wout_best, model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026f73c8-0861-4769-9720-91b61bc3b2cf",
   "metadata": {},
   "source": [
    "# Evaluate saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "92bcf44b-3783-4ebb-a302-6e66b521ab22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metrics over train dataset:\n",
      "Accuracy: 0.9751\n",
      "Precision: 0.9636\n",
      "Recall: 0.9599\n",
      "F1 Score: 0.9617\n",
      "\n",
      "Class 0 Metrics\n",
      "Accuracy: 0.9956\n",
      "Precision: 0.9911\n",
      "Recall: 0.9918\n",
      "F1 Score: 0.9914\n",
      "\n",
      "Class 1 Metrics\n",
      "Accuracy: 0.9636\n",
      "Precision: 0.9412\n",
      "Recall: 0.9160\n",
      "F1 Score: 0.9284\n",
      "\n",
      "Class 2 Metrics\n",
      "Accuracy: 0.9661\n",
      "Precision: 0.9587\n",
      "Recall: 0.9719\n",
      "F1 Score: 0.9653\n",
      "\n",
      "\n",
      "Average Metrics over test dataset:\n",
      "Accuracy: 0.8120\n",
      "Precision: 0.7471\n",
      "Recall: 0.7120\n",
      "F1 Score: 0.6974\n",
      "\n",
      "Class 0 Metrics\n",
      "Accuracy: 0.8157\n",
      "Precision: 0.9837\n",
      "Recall: 0.5171\n",
      "F1 Score: 0.6779\n",
      "\n",
      "Class 1 Metrics\n",
      "Accuracy: 0.7612\n",
      "Precision: 0.4976\n",
      "Recall: 0.6892\n",
      "F1 Score: 0.5779\n",
      "\n",
      "Class 2 Metrics\n",
      "Accuracy: 0.8590\n",
      "Precision: 0.7601\n",
      "Recall: 0.9298\n",
      "F1 Score: 0.8364\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"loggers/resnet_from_scratch/resnet_from_scratch.pkl\", 'rb') as f:\n",
    "    best_model = pickle.load(f)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "best_model = best_model.to(device)\n",
    "best_model.eval()\n",
    "all_preds_tensor1x = evaluate_model_x(train_dataloader2, test_dataloader, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "743b3739-3215-42c6-9057-b5e5823aedfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metrics over train dataset:\n",
      "Accuracy: 0.9822\n",
      "Precision: 0.9738\n",
      "Recall: 0.9731\n",
      "F1 Score: 0.9734\n",
      "\n",
      "Class 0 Metrics\n",
      "Accuracy: 0.9988\n",
      "Precision: 0.9963\n",
      "Recall: 0.9993\n",
      "F1 Score: 0.9978\n",
      "\n",
      "Class 1 Metrics\n",
      "Accuracy: 0.9741\n",
      "Precision: 0.9535\n",
      "Recall: 0.9457\n",
      "F1 Score: 0.9496\n",
      "\n",
      "Class 2 Metrics\n",
      "Accuracy: 0.9737\n",
      "Precision: 0.9716\n",
      "Recall: 0.9743\n",
      "F1 Score: 0.9730\n",
      "\n",
      "\n",
      "Average Metrics over test dataset:\n",
      "Accuracy: 0.8376\n",
      "Precision: 0.7756\n",
      "Recall: 0.7465\n",
      "F1 Score: 0.7354\n",
      "\n",
      "Class 0 Metrics\n",
      "Accuracy: 0.8365\n",
      "Precision: 0.9925\n",
      "Recall: 0.5684\n",
      "F1 Score: 0.7228\n",
      "\n",
      "Class 1 Metrics\n",
      "Accuracy: 0.8061\n",
      "Precision: 0.5754\n",
      "Recall: 0.6959\n",
      "F1 Score: 0.6300\n",
      "\n",
      "Class 2 Metrics\n",
      "Accuracy: 0.8702\n",
      "Precision: 0.7588\n",
      "Recall: 0.9752\n",
      "F1 Score: 0.8535\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"loggers/resnet_transferlearn/resnet_transferlearn.pkl\", 'rb') as f:\n",
    "    best_model = pickle.load(f)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "best_model = best_model.to(device)\n",
    "best_model.eval()\n",
    "all_preds_tensor2x = evaluate_model_x(train_dataloader2, test_dataloader, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c5bb5f71-4d99-4538-b9b0-142619190c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metrics over train dataset:\n",
      "Accuracy: 0.8612\n",
      "Precision: 0.7822\n",
      "Recall: 0.7913\n",
      "F1 Score: 0.7863\n",
      "\n",
      "Class 0 Metrics\n",
      "Accuracy: 0.9517\n",
      "Precision: 0.8794\n",
      "Recall: 0.9411\n",
      "F1 Score: 0.9092\n",
      "\n",
      "Class 1 Metrics\n",
      "Accuracy: 0.8184\n",
      "Precision: 0.6508\n",
      "Recall: 0.6387\n",
      "F1 Score: 0.6447\n",
      "\n",
      "Class 2 Metrics\n",
      "Accuracy: 0.8135\n",
      "Precision: 0.8163\n",
      "Recall: 0.7941\n",
      "F1 Score: 0.8050\n",
      "\n",
      "\n",
      "Average Metrics over test dataset:\n",
      "Accuracy: 0.8600\n",
      "Precision: 0.7937\n",
      "Recall: 0.7935\n",
      "F1 Score: 0.7782\n",
      "\n",
      "Class 0 Metrics\n",
      "Accuracy: 0.8397\n",
      "Precision: 0.9241\n",
      "Recall: 0.6239\n",
      "F1 Score: 0.7449\n",
      "\n",
      "Class 1 Metrics\n",
      "Accuracy: 0.8413\n",
      "Precision: 0.6244\n",
      "Recall: 0.8311\n",
      "F1 Score: 0.7130\n",
      "\n",
      "Class 2 Metrics\n",
      "Accuracy: 0.8990\n",
      "Precision: 0.8327\n",
      "Recall: 0.9256\n",
      "F1 Score: 0.8767\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"loggers/resnet_finetuning/resnet_finetuning.pkl\", 'rb') as f:\n",
    "    best_model = pickle.load(f)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "best_model = best_model.to(device)\n",
    "best_model.eval()\n",
    "all_preds_tensor3x = evaluate_model_x(train_dataloader2, test_dataloader, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "4d53591a-ab05-4c5e-8b1e-e25980dd3429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metrics over train dataset:\n",
      "Accuracy: 0.8912\n",
      "Precision: 0.8405\n",
      "Recall: 0.8257\n",
      "F1 Score: 0.8319\n",
      "\n",
      "Class 0 Metrics\n",
      "Accuracy: 0.9837\n",
      "Precision: 0.9772\n",
      "Recall: 0.9590\n",
      "F1 Score: 0.9680\n",
      "\n",
      "Class 1 Metrics\n",
      "Accuracy: 0.8459\n",
      "Precision: 0.7275\n",
      "Recall: 0.6431\n",
      "F1 Score: 0.6827\n",
      "\n",
      "Class 2 Metrics\n",
      "Accuracy: 0.8441\n",
      "Precision: 0.8167\n",
      "Recall: 0.8751\n",
      "F1 Score: 0.8449\n",
      "\n",
      "\n",
      "Average Metrics over test dataset:\n",
      "Accuracy: 0.8429\n",
      "Precision: 0.7868\n",
      "Recall: 0.7653\n",
      "F1 Score: 0.7469\n",
      "\n",
      "Class 0 Metrics\n",
      "Accuracy: 0.8205\n",
      "Precision: 0.9766\n",
      "Recall: 0.5342\n",
      "F1 Score: 0.6906\n",
      "\n",
      "Class 1 Metrics\n",
      "Accuracy: 0.8333\n",
      "Precision: 0.6158\n",
      "Recall: 0.7905\n",
      "F1 Score: 0.6923\n",
      "\n",
      "Class 2 Metrics\n",
      "Accuracy: 0.8750\n",
      "Precision: 0.7680\n",
      "Recall: 0.9711\n",
      "F1 Score: 0.8577\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"loggers/dino_finetuning/dino_finetuning.pkl\", 'rb') as f:\n",
    "    best_model = pickle.load(f)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "best_model = best_model.to(device)\n",
    "best_model.eval()\n",
    "all_preds_tensor4x = evaluate_model_x(train_dataloader2, test_dataloader, best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ed4c2a-e19a-4126-a7c7-f99ba3f9f213",
   "metadata": {},
   "source": [
    "# Calculating Pairwise McNemar-Bowker Test for 7 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9139459c-080f-4113-ba27-a99caf434e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = []\n",
    "for k, (y, x) in enumerate(test_dataloader):  \n",
    "    all_labels.extend([x[0].cpu()])\n",
    "all_labels_tensor = torch.tensor(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0839fa38-a6aa-4d0f-9347-e9573ed4bac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison between Classifier 1 and Classifier 2: Chi2 Statistic = 20.418, P-value = 0.000\n",
      "Comparison between Classifier 1 and Classifier 3: Chi2 Statistic = 10.746, P-value = 0.013\n",
      "Comparison between Classifier 1 and Classifier 4: Chi2 Statistic = 53.319, P-value = 0.000\n",
      "Comparison between Classifier 1 and Classifier 5: Chi2 Statistic = 41.503, P-value = 0.000\n",
      "Comparison between Classifier 1 and Classifier 6: Chi2 Statistic = 30.145, P-value = 0.000\n",
      "Comparison between Classifier 1 and Classifier 7: Chi2 Statistic = 48.464, P-value = 0.000\n",
      "Comparison between Classifier 2 and Classifier 3: Chi2 Statistic = 6.710, P-value = 0.082\n",
      "Comparison between Classifier 2 and Classifier 4: Chi2 Statistic = 44.416, P-value = 0.000\n",
      "Comparison between Classifier 2 and Classifier 5: Chi2 Statistic = 29.108, P-value = 0.000\n",
      "Comparison between Classifier 2 and Classifier 6: Chi2 Statistic = 48.372, P-value = 0.000\n",
      "Comparison between Classifier 2 and Classifier 7: Chi2 Statistic = 35.427, P-value = 0.000\n",
      "Comparison between Classifier 3 and Classifier 4: Chi2 Statistic = 25.482, P-value = 0.000\n",
      "Comparison between Classifier 3 and Classifier 5: Chi2 Statistic = 12.925, P-value = 0.005\n",
      "Comparison between Classifier 3 and Classifier 6: Chi2 Statistic = 26.173, P-value = 0.000\n",
      "Comparison between Classifier 3 and Classifier 7: Chi2 Statistic = 17.489, P-value = 0.001\n",
      "Comparison between Classifier 4 and Classifier 5: Chi2 Statistic = 5.890, P-value = 0.117\n",
      "Comparison between Classifier 4 and Classifier 6: Chi2 Statistic = 19.573, P-value = 0.000\n",
      "Comparison between Classifier 4 and Classifier 7: Chi2 Statistic = 6.947, P-value = 0.074\n",
      "Comparison between Classifier 5 and Classifier 6: Chi2 Statistic = 26.767, P-value = 0.000\n",
      "Comparison between Classifier 5 and Classifier 7: Chi2 Statistic = 17.020, P-value = 0.001\n",
      "Comparison between Classifier 6 and Classifier 7: Chi2 Statistic = 22.843, P-value = 0.000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming you have the true labels and predictions from 7 classifiers\n",
    "true_labels = all_labels_tensor.numpy()  # True labels of the test set\n",
    "predictions = [all_preds_tensor1.numpy(),\n",
    "               all_preds_tensor2.numpy(),\n",
    "               all_preds_tensor3.numpy(),\n",
    "               all_preds_tensor1x.numpy(),\n",
    "               all_preds_tensor2x.numpy(),\n",
    "               all_preds_tensor3x.numpy(),\n",
    "               all_preds_tensor4x.numpy()]\n",
    "\n",
    "# McNemar-Bowker test function\n",
    "def mcnemar_bowker_test(conf_matrix):\n",
    "    k = conf_matrix.shape[0]\n",
    "    chi2_statistic = 0\n",
    "    for i in range(k):\n",
    "        for j in range(i + 1, k):\n",
    "            chi2_statistic += (conf_matrix[i, j] - conf_matrix[j, i])**2 / (conf_matrix[i, j] + conf_matrix[j, i] + 1e-9)\n",
    "    \n",
    "    p_value = 1 - chi2.cdf(chi2_statistic, df=k * (k - 1) / 2)\n",
    "    return {'chi2_statistic': chi2_statistic, 'p_value': p_value}\n",
    "\n",
    "# Generate pairwise confusion matrices and perform McNemar-Bowker test\n",
    "num_classifiers = len(predictions)\n",
    "results = {}\n",
    "\n",
    "for i in range(num_classifiers):\n",
    "    for j in range(i + 1, num_classifiers):\n",
    "        pairwise_matrix = np.zeros((3, 3)) \n",
    "        for true_label, pred_i, pred_j in zip(true_labels, predictions[i], predictions[j]):\n",
    "            pairwise_matrix[pred_i, pred_j] += 1  \n",
    "        test_result = mcnemar_bowker_test(pairwise_matrix)\n",
    "        results[(i + 1, j + 1)] = test_result\n",
    "\n",
    "# Print the results\n",
    "for pair, result in results.items():\n",
    "    print(f\"Comparison between Classifier {pair[0]} and Classifier {pair[1]}: Chi2 Statistic = {result['chi2_statistic']:.3f}, P-value = {result['p_value']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9f0f3b-f881-4abd-8940-b4b0808d6bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
